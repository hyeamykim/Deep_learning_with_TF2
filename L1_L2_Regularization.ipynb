{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L1_L2_Regularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUmecs2bXdww"
      },
      "source": [
        "# Load pacakages\n",
        "Use the standar packages from Google Colab unless stated otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xpPocB6vlDu"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLOgrstp61hS"
      },
      "source": [
        "Load necessary libraries and check the versions of the important ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr3-yF_1XGO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5317f72-6006-4fc5-c5e7-30f3cf4e5f0a"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pk\n",
        "from google.colab import drive\n",
        "\n",
        "# !pip install --upgrade tensorflow\n",
        "# drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# sig1=np.load('/content/gdrive/My Drive/data1.npy')\n",
        "# sig2=np.load('/content/gdrive/My Drive/data2.npy')\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(pd.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "1.18.5\n",
            "1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bD2az2VXwtx"
      },
      "source": [
        "# Load data function\n",
        "In this problem, we are defining our dataset; X as random 5 numbers and y as sum of sine of X's and sum of cosine of X's.\n",
        "\n",
        "In the training set, there are 16000 instances and in the test set, there are 160 instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8w13xdzXtNe"
      },
      "source": [
        "def loadTrainData (default_dir=\"/default/path/if/needed\"):\n",
        "  x = np.random.rand(16000,5) # write data loading procedures for train set\n",
        "  y1 = np.array([np.sin(x).sum(axis=1)])\n",
        "  y2 = np.array([np.cos(x).sum(axis=1)])\n",
        "  y = np.concatenate((y1.T, y2.T), axis=1)\n",
        "  # print(x.shape, y.shape) # just to check dimensions\n",
        "  return x, y\n",
        "\n",
        "def loadTestData (default_dir=\"/default/path/if/needed\"):\n",
        "  x = np.random.rand(160,5) # write data loading procedures for test set\n",
        "  y1 = np.array([np.sin(x).sum(axis=1)])\n",
        "  y2 = np.array([np.cos(x).sum(axis=1)])\n",
        "  y = np.concatenate((y1.T, y2.T), axis=1)\n",
        "  # print(x.shape, y.shape)\n",
        "  return x , y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXqbGWED6Opn"
      },
      "source": [
        "Check data loading function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEL_fiqFD0yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4a4360-49bb-4895-ede5-a1471cdd39d9"
      },
      "source": [
        "loadTestData()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.54903505e-01, 8.40938945e-01, 5.26292370e-01, 6.15694181e-01,\n",
              "         2.94747863e-01],\n",
              "        [5.21287126e-01, 7.35120535e-01, 7.23246225e-01, 5.00936441e-01,\n",
              "         7.71381139e-01],\n",
              "        [9.02328744e-01, 7.07188915e-01, 3.05570208e-01, 5.44349943e-02,\n",
              "         6.57361465e-01],\n",
              "        [8.31282516e-01, 5.08520760e-01, 6.43637711e-01, 2.87807400e-01,\n",
              "         1.62950295e-01],\n",
              "        [9.02043445e-01, 4.65152025e-01, 3.25964400e-02, 4.28115774e-01,\n",
              "         2.55051206e-01],\n",
              "        [2.37587821e-01, 1.04351251e-01, 7.97906932e-01, 9.06377809e-01,\n",
              "         1.58162212e-01],\n",
              "        [1.02544741e-01, 6.09728072e-01, 2.79295319e-01, 6.24490504e-01,\n",
              "         7.32386801e-01],\n",
              "        [1.91598206e-01, 1.35537938e-01, 9.33448675e-01, 4.75262419e-01,\n",
              "         5.86791108e-01],\n",
              "        [5.54311177e-01, 2.91972124e-01, 8.30451787e-02, 7.98355491e-01,\n",
              "         7.23407148e-01],\n",
              "        [4.13797176e-01, 4.19493622e-01, 3.53353176e-01, 7.13317439e-01,\n",
              "         7.12090443e-01],\n",
              "        [9.44825129e-01, 6.83808659e-01, 3.57122590e-01, 8.42947624e-01,\n",
              "         8.68019328e-01],\n",
              "        [7.46533053e-01, 2.35388958e-01, 8.85795638e-01, 7.70874030e-03,\n",
              "         8.66723846e-01],\n",
              "        [8.54696332e-01, 1.23365940e-01, 3.95340241e-01, 7.31145698e-01,\n",
              "         8.58588155e-01],\n",
              "        [6.65522265e-01, 1.55122195e-01, 3.73412196e-02, 8.86952449e-01,\n",
              "         5.80913462e-01],\n",
              "        [6.56900832e-01, 6.91792380e-01, 4.20828169e-01, 7.64302407e-01,\n",
              "         8.19307112e-01],\n",
              "        [7.71970760e-01, 4.32365452e-01, 4.37972223e-01, 2.97691061e-01,\n",
              "         6.18574030e-01],\n",
              "        [5.87801991e-01, 4.13540195e-01, 2.65144697e-01, 1.03595348e-01,\n",
              "         1.99101869e-01],\n",
              "        [5.99428362e-01, 9.27161313e-01, 7.77205846e-01, 4.33236144e-01,\n",
              "         9.07287107e-01],\n",
              "        [2.92483579e-01, 1.16287023e-01, 7.11638407e-02, 3.87679121e-01,\n",
              "         6.76734797e-01],\n",
              "        [2.83360223e-01, 7.45336757e-01, 1.19552442e-01, 2.62872301e-01,\n",
              "         4.09234949e-01],\n",
              "        [9.47782598e-01, 8.51673282e-01, 1.64290618e-01, 5.22975775e-02,\n",
              "         1.50340065e-01],\n",
              "        [6.71774274e-01, 8.49973016e-02, 7.01401555e-01, 4.04536352e-02,\n",
              "         7.10412039e-01],\n",
              "        [8.31653507e-01, 2.55788518e-02, 8.85377636e-01, 7.71202830e-01,\n",
              "         7.27495902e-01],\n",
              "        [1.16946278e-01, 6.39998407e-01, 3.82227900e-01, 9.68805696e-01,\n",
              "         2.10328969e-02],\n",
              "        [2.37413075e-01, 4.49395248e-01, 2.43362732e-01, 4.61141796e-01,\n",
              "         1.02299651e-01],\n",
              "        [4.64368978e-01, 8.58839996e-01, 6.39492238e-01, 3.51006257e-01,\n",
              "         2.56399693e-01],\n",
              "        [3.86259608e-01, 8.84232091e-01, 7.65009273e-01, 3.88114284e-01,\n",
              "         4.17600674e-01],\n",
              "        [7.68423023e-01, 4.31185228e-01, 1.24722793e-02, 7.83765536e-01,\n",
              "         4.82180637e-01],\n",
              "        [7.82314785e-02, 1.43743910e-01, 7.29681313e-01, 2.99218640e-01,\n",
              "         9.96155478e-01],\n",
              "        [6.18291777e-01, 5.59814582e-01, 7.35943841e-01, 4.96205234e-01,\n",
              "         4.68610250e-01],\n",
              "        [7.72106655e-01, 8.04070773e-01, 2.26015089e-01, 9.39185618e-01,\n",
              "         5.94128410e-01],\n",
              "        [9.70846342e-01, 2.65759651e-02, 3.87771632e-01, 8.62667093e-01,\n",
              "         8.61364062e-01],\n",
              "        [1.54962618e-01, 7.30857857e-01, 4.05441822e-01, 7.22377224e-01,\n",
              "         4.35347533e-01],\n",
              "        [3.89871032e-01, 9.30123615e-01, 1.99535138e-01, 3.24673801e-01,\n",
              "         1.21233327e-01],\n",
              "        [8.66478861e-01, 1.74799871e-02, 9.47022903e-01, 5.94934216e-01,\n",
              "         1.69249892e-01],\n",
              "        [2.35516453e-01, 7.71535389e-01, 1.20994132e-02, 9.38542023e-01,\n",
              "         3.80360132e-02],\n",
              "        [8.54138852e-02, 7.56002612e-01, 8.37306874e-03, 8.98404691e-01,\n",
              "         3.36490389e-01],\n",
              "        [9.41207927e-01, 3.10575108e-01, 3.10487349e-01, 3.89933932e-01,\n",
              "         9.76824953e-01],\n",
              "        [1.58851536e-01, 7.05368984e-01, 4.56911283e-01, 1.27809141e-02,\n",
              "         9.92743599e-01],\n",
              "        [9.32270390e-01, 5.15218915e-01, 4.70419037e-01, 1.95539422e-01,\n",
              "         3.09504220e-01],\n",
              "        [4.15062655e-01, 7.15904160e-01, 4.90360471e-01, 3.27252102e-01,\n",
              "         3.83237326e-01],\n",
              "        [6.26863939e-01, 8.09127821e-01, 8.50026781e-01, 1.77645423e-01,\n",
              "         1.41242859e-02],\n",
              "        [5.31257367e-01, 3.36645653e-01, 4.29251407e-01, 3.04802033e-01,\n",
              "         2.97928961e-01],\n",
              "        [1.49574797e-01, 8.81227537e-01, 4.91373802e-01, 8.82273966e-03,\n",
              "         9.43276879e-01],\n",
              "        [1.07549153e-01, 1.05930104e-01, 5.00936373e-01, 4.40211693e-01,\n",
              "         1.51744330e-01],\n",
              "        [1.58719649e-01, 9.99475792e-01, 2.84481962e-01, 1.47173189e-01,\n",
              "         6.88691738e-01],\n",
              "        [8.81710831e-01, 1.58440561e-01, 5.48775518e-02, 5.04684080e-01,\n",
              "         6.77266358e-01],\n",
              "        [5.20938264e-02, 9.53781533e-01, 8.60040988e-01, 5.10283996e-02,\n",
              "         4.73421500e-01],\n",
              "        [2.98677125e-01, 1.14198247e-02, 1.63178470e-01, 2.56029913e-01,\n",
              "         1.59408519e-01],\n",
              "        [5.20310164e-01, 3.14922200e-02, 2.11208729e-01, 3.20692759e-01,\n",
              "         4.44723166e-01],\n",
              "        [5.93769524e-01, 3.04090385e-01, 2.05686870e-02, 5.34748723e-01,\n",
              "         9.97529223e-01],\n",
              "        [4.56367607e-01, 4.96972971e-02, 5.90007184e-01, 1.70853613e-01,\n",
              "         2.31038245e-01],\n",
              "        [3.87248935e-02, 5.36455855e-01, 2.48044375e-01, 7.57774475e-01,\n",
              "         3.42032428e-01],\n",
              "        [1.41144755e-01, 8.91340898e-01, 8.03695215e-02, 3.73779173e-01,\n",
              "         4.01898393e-02],\n",
              "        [5.48569015e-01, 4.30768566e-01, 2.30677410e-01, 1.49881913e-02,\n",
              "         4.46095425e-01],\n",
              "        [4.30730500e-01, 4.49827855e-01, 7.14761775e-03, 6.93667303e-01,\n",
              "         9.77986806e-01],\n",
              "        [5.10496008e-01, 8.76837909e-01, 9.01762362e-01, 4.03315595e-02,\n",
              "         6.40842101e-01],\n",
              "        [1.97459840e-01, 3.17725637e-01, 3.18354412e-01, 8.72763460e-01,\n",
              "         5.81673874e-01],\n",
              "        [6.32494516e-01, 5.14791475e-01, 6.67482004e-02, 3.73464207e-01,\n",
              "         5.52911644e-01],\n",
              "        [7.45553464e-04, 9.88355270e-02, 6.85228621e-01, 6.70707831e-01,\n",
              "         4.59788541e-01],\n",
              "        [2.50182292e-01, 6.35385898e-01, 7.15039234e-01, 8.08444315e-01,\n",
              "         5.43578824e-01],\n",
              "        [8.28652904e-02, 1.92960749e-01, 7.32715499e-01, 1.41234684e-01,\n",
              "         4.90451346e-01],\n",
              "        [8.95214112e-01, 4.87376930e-01, 2.82651707e-01, 9.76804818e-01,\n",
              "         3.50152139e-01],\n",
              "        [6.71783619e-01, 6.89017208e-01, 2.03004068e-01, 6.48813531e-02,\n",
              "         3.87376460e-01],\n",
              "        [5.50564444e-01, 2.22346211e-01, 6.74467483e-01, 8.73060516e-01,\n",
              "         4.75639736e-01],\n",
              "        [4.77453129e-01, 9.52977331e-01, 2.28549439e-01, 8.65456425e-01,\n",
              "         4.57401584e-01],\n",
              "        [6.80689483e-02, 4.24879646e-01, 1.49487166e-01, 8.85679251e-01,\n",
              "         2.76503559e-01],\n",
              "        [6.97098631e-01, 1.78653522e-01, 6.15018167e-01, 5.29246894e-01,\n",
              "         4.64546914e-01],\n",
              "        [5.02598242e-02, 8.87109655e-01, 2.52899672e-01, 5.60591664e-01,\n",
              "         8.14232342e-01],\n",
              "        [8.33753013e-01, 8.19938869e-01, 2.50570042e-01, 8.88947312e-01,\n",
              "         9.31758045e-01],\n",
              "        [7.73740754e-01, 2.25382625e-01, 7.63451531e-01, 2.49644650e-01,\n",
              "         6.72859405e-02],\n",
              "        [6.52526539e-01, 6.55300243e-02, 1.97369547e-01, 1.00253780e-01,\n",
              "         4.48067697e-01],\n",
              "        [2.21825849e-02, 1.62230061e-01, 9.45117043e-01, 1.51423709e-01,\n",
              "         6.12521703e-01],\n",
              "        [1.10007885e-01, 5.51535752e-01, 3.00701306e-01, 2.00380816e-01,\n",
              "         4.87478327e-01],\n",
              "        [6.21489373e-01, 9.51532389e-02, 4.10209343e-01, 8.35089836e-01,\n",
              "         7.06847187e-01],\n",
              "        [1.44710231e-01, 3.97829761e-01, 5.14957142e-01, 2.42283967e-01,\n",
              "         4.27389335e-01],\n",
              "        [2.35309726e-01, 8.14240289e-02, 6.20490808e-01, 2.90332007e-01,\n",
              "         9.84929460e-01],\n",
              "        [6.00364527e-01, 7.48583564e-01, 1.10528449e-01, 7.96941347e-01,\n",
              "         7.88484964e-01],\n",
              "        [7.32708329e-01, 6.64482451e-02, 9.40096711e-01, 9.50970264e-01,\n",
              "         3.07787197e-01],\n",
              "        [8.75534511e-01, 6.97684411e-01, 1.37560915e-01, 6.51582221e-01,\n",
              "         6.02978496e-01],\n",
              "        [6.83103246e-01, 6.13841062e-01, 3.83847891e-01, 8.93275102e-02,\n",
              "         4.79917929e-01],\n",
              "        [2.10786156e-01, 3.82279142e-01, 7.52659078e-01, 3.29515258e-01,\n",
              "         6.23252158e-01],\n",
              "        [3.11169188e-01, 8.99449803e-01, 6.59276998e-01, 3.57155336e-02,\n",
              "         2.40601719e-01],\n",
              "        [7.85640128e-01, 3.52092014e-01, 9.21486120e-01, 7.36112331e-02,\n",
              "         1.99931705e-02],\n",
              "        [5.73407158e-01, 4.35308394e-01, 7.21184916e-01, 3.78876848e-01,\n",
              "         3.14884144e-01],\n",
              "        [8.25221299e-02, 9.36885298e-01, 5.17936898e-01, 9.36032232e-01,\n",
              "         4.09856087e-02],\n",
              "        [5.16931876e-01, 6.69763595e-01, 2.42391648e-02, 7.09513580e-01,\n",
              "         9.06760871e-01],\n",
              "        [2.59889457e-01, 7.55100059e-01, 3.22904875e-01, 8.91282037e-01,\n",
              "         1.36157652e-01],\n",
              "        [1.87488788e-02, 9.41701323e-01, 4.34157072e-01, 7.51115050e-01,\n",
              "         1.86873173e-01],\n",
              "        [8.84049590e-01, 6.32202123e-01, 2.42000521e-01, 8.03102473e-01,\n",
              "         6.92808450e-01],\n",
              "        [9.53644924e-01, 6.47942226e-01, 9.46478128e-02, 4.99688513e-01,\n",
              "         2.27419637e-01],\n",
              "        [7.84470381e-01, 6.65006218e-01, 3.69000757e-01, 3.88357520e-01,\n",
              "         2.55074978e-01],\n",
              "        [6.62698210e-01, 2.99853899e-01, 1.58902805e-02, 9.82543351e-01,\n",
              "         4.67194037e-01],\n",
              "        [3.09972592e-01, 8.40713381e-01, 7.46778252e-01, 4.11262751e-01,\n",
              "         1.41519944e-01],\n",
              "        [8.06850720e-01, 7.73142577e-01, 3.03023834e-01, 8.59707935e-01,\n",
              "         7.11670264e-01],\n",
              "        [4.63671658e-01, 5.04621753e-01, 1.82748953e-01, 5.40913546e-01,\n",
              "         4.10710941e-01],\n",
              "        [1.62757248e-01, 9.51858302e-01, 9.10298466e-01, 3.59625379e-01,\n",
              "         7.35032297e-01],\n",
              "        [5.87841246e-01, 1.73169128e-01, 1.43562258e-01, 7.37935161e-01,\n",
              "         7.60032357e-01],\n",
              "        [7.19754507e-02, 1.05709677e-01, 4.52288994e-01, 4.14240485e-01,\n",
              "         3.11849906e-01],\n",
              "        [4.94368957e-01, 8.78001256e-01, 9.21832748e-01, 4.35020301e-01,\n",
              "         4.42372799e-02],\n",
              "        [4.09020380e-01, 1.70635788e-01, 3.08675917e-01, 3.75828973e-01,\n",
              "         5.88834648e-01],\n",
              "        [6.64265482e-01, 3.83137166e-01, 4.81786345e-01, 9.99069844e-01,\n",
              "         7.77236711e-01],\n",
              "        [1.36638726e-01, 8.38048220e-01, 5.37045115e-01, 9.64452162e-01,\n",
              "         6.71638887e-01],\n",
              "        [5.51318444e-01, 7.95388418e-01, 5.26556817e-01, 7.26678049e-01,\n",
              "         9.85025891e-02],\n",
              "        [4.54641490e-01, 2.62280926e-01, 7.16174113e-01, 5.07488500e-02,\n",
              "         3.55213772e-01],\n",
              "        [8.47971699e-01, 1.44987709e-02, 9.41666248e-01, 9.07104584e-01,\n",
              "         8.86247784e-01],\n",
              "        [7.28890492e-01, 7.67151369e-01, 8.57017764e-01, 7.20988875e-01,\n",
              "         9.22178774e-01],\n",
              "        [3.62745790e-02, 5.67102472e-01, 4.46519016e-01, 9.71883516e-01,\n",
              "         1.54648428e-01],\n",
              "        [6.32998852e-01, 1.35643206e-01, 7.32521913e-01, 8.62511283e-01,\n",
              "         2.34097732e-01],\n",
              "        [9.59169165e-01, 3.33402964e-01, 5.23311676e-01, 1.68567357e-01,\n",
              "         4.29473500e-01],\n",
              "        [4.93906581e-01, 4.03124384e-01, 3.76588321e-01, 8.14057274e-01,\n",
              "         4.59648042e-01],\n",
              "        [8.04243688e-01, 7.46524676e-01, 4.39820366e-01, 1.51971077e-01,\n",
              "         5.11075531e-01],\n",
              "        [2.84789062e-03, 6.46245838e-01, 6.84944146e-03, 8.62601165e-01,\n",
              "         8.13048072e-01],\n",
              "        [9.77828895e-01, 4.49569832e-01, 1.11082727e-01, 6.86685199e-01,\n",
              "         6.43642467e-01],\n",
              "        [2.35839558e-01, 4.91612989e-01, 7.61502293e-01, 2.51691264e-01,\n",
              "         9.78092401e-02],\n",
              "        [9.38639495e-01, 6.69933902e-01, 5.84970732e-01, 6.24294210e-01,\n",
              "         2.77456474e-01],\n",
              "        [4.50393322e-02, 5.07747881e-01, 2.40821133e-01, 1.65060389e-01,\n",
              "         4.47614673e-01],\n",
              "        [9.85779944e-04, 9.51066048e-01, 6.67109504e-01, 5.90090563e-01,\n",
              "         6.03319082e-01],\n",
              "        [6.04382473e-01, 5.41987412e-01, 3.37955188e-01, 9.71161884e-01,\n",
              "         6.19094472e-01],\n",
              "        [6.26304032e-01, 9.67559222e-01, 3.81033506e-02, 6.85483570e-02,\n",
              "         3.83208464e-01],\n",
              "        [4.32925689e-01, 5.54626615e-01, 3.29318131e-01, 7.12859726e-01,\n",
              "         3.67359077e-01],\n",
              "        [3.27032212e-01, 4.92182874e-01, 9.89449066e-01, 1.55397189e-01,\n",
              "         5.84932540e-01],\n",
              "        [3.61630164e-01, 1.19431883e-02, 9.63694044e-01, 3.73697067e-02,\n",
              "         9.76360359e-01],\n",
              "        [6.87671795e-01, 3.58338666e-01, 8.41743330e-01, 5.64373090e-01,\n",
              "         5.19244382e-01],\n",
              "        [3.25698122e-01, 1.19646523e-01, 7.53953077e-01, 6.88421752e-01,\n",
              "         6.98550250e-01],\n",
              "        [8.52009384e-01, 8.91685780e-01, 2.20055210e-01, 9.37071046e-01,\n",
              "         6.73019536e-01],\n",
              "        [3.27836350e-01, 6.67802414e-01, 2.58580410e-01, 4.90684994e-03,\n",
              "         5.89256755e-01],\n",
              "        [4.73387024e-01, 5.52897379e-01, 4.64564695e-01, 2.94678919e-01,\n",
              "         4.48105345e-01],\n",
              "        [7.69664789e-01, 1.01516527e-01, 9.41187331e-01, 2.66130497e-01,\n",
              "         7.05284537e-01],\n",
              "        [5.28718945e-01, 5.01195767e-01, 4.80368270e-01, 7.27062932e-01,\n",
              "         9.96059374e-01],\n",
              "        [7.12534175e-02, 5.44842115e-01, 8.25177701e-01, 7.24932434e-01,\n",
              "         7.01599269e-01],\n",
              "        [6.30912459e-01, 5.05959141e-01, 2.28869978e-01, 6.61706116e-01,\n",
              "         7.07269369e-01],\n",
              "        [5.78077391e-01, 4.66509961e-01, 2.36205408e-01, 6.87586814e-01,\n",
              "         8.80396907e-01],\n",
              "        [3.06514248e-01, 9.96251410e-01, 4.21046413e-01, 1.85398140e-01,\n",
              "         6.83505162e-01],\n",
              "        [9.03454257e-01, 6.90759768e-01, 3.93086297e-01, 3.98268121e-02,\n",
              "         8.42720581e-01],\n",
              "        [9.51367146e-01, 8.58100780e-01, 6.91901191e-01, 3.55835187e-01,\n",
              "         1.31596737e-01],\n",
              "        [4.44446034e-01, 7.10067769e-01, 7.81615314e-01, 8.96165701e-01,\n",
              "         7.01794414e-01],\n",
              "        [3.74090383e-01, 5.88805961e-01, 6.35697904e-01, 2.34628464e-01,\n",
              "         5.43220970e-01],\n",
              "        [9.14606684e-01, 4.53736056e-01, 9.32451190e-01, 5.24621759e-01,\n",
              "         1.93376912e-01],\n",
              "        [2.50677706e-02, 1.23153642e-01, 1.76337544e-01, 8.62168523e-01,\n",
              "         8.48769433e-01],\n",
              "        [3.97434883e-01, 8.61996391e-01, 5.48072410e-01, 1.58390828e-03,\n",
              "         1.93016398e-01],\n",
              "        [6.16472269e-01, 8.31305319e-01, 5.95536795e-01, 5.82259288e-01,\n",
              "         8.09540117e-01],\n",
              "        [5.06498558e-01, 5.31130253e-02, 5.48797028e-01, 4.33358595e-01,\n",
              "         7.85945306e-01],\n",
              "        [9.45673470e-01, 6.44742657e-01, 1.95613735e-01, 7.57254352e-01,\n",
              "         4.76793935e-01],\n",
              "        [6.36663708e-01, 7.33354731e-01, 4.87225962e-01, 7.50264539e-01,\n",
              "         7.73654645e-01],\n",
              "        [4.52416024e-01, 6.62586636e-01, 2.27095626e-01, 2.85550079e-01,\n",
              "         1.34206786e-01],\n",
              "        [1.97623202e-03, 2.79658965e-01, 9.73109197e-01, 4.09336573e-01,\n",
              "         8.09457929e-01],\n",
              "        [2.21044827e-01, 7.66904671e-01, 6.05853416e-01, 3.41390687e-01,\n",
              "         8.59072486e-01],\n",
              "        [6.08572536e-01, 2.65904930e-01, 1.23678048e-01, 5.47975481e-01,\n",
              "         7.16178923e-01],\n",
              "        [4.54104977e-01, 6.46436527e-01, 5.52506717e-01, 4.91938682e-01,\n",
              "         2.59154910e-01],\n",
              "        [2.68406157e-01, 9.83437014e-01, 6.72781793e-01, 2.83597078e-01,\n",
              "         8.99036466e-01],\n",
              "        [6.53906698e-01, 5.42565575e-02, 1.59348144e-01, 7.75417924e-01,\n",
              "         4.67841119e-01],\n",
              "        [2.14109049e-01, 1.52372531e-01, 1.53889114e-01, 6.91644033e-01,\n",
              "         7.44825593e-01],\n",
              "        [5.67621042e-01, 3.70695866e-01, 6.36076752e-01, 6.55726017e-01,\n",
              "         7.04991433e-01],\n",
              "        [2.17396680e-01, 7.21946263e-01, 5.66840676e-01, 1.71532322e-01,\n",
              "         8.64009712e-01],\n",
              "        [2.75417280e-01, 8.58445327e-01, 4.89644800e-01, 1.78106945e-02,\n",
              "         1.33309371e-02],\n",
              "        [7.85237191e-01, 7.38169195e-01, 4.68044528e-01, 9.77121237e-01,\n",
              "         7.71523320e-01],\n",
              "        [7.05938602e-01, 5.35438508e-01, 7.57475840e-01, 7.03722182e-01,\n",
              "         7.23272640e-01],\n",
              "        [1.83134458e-01, 2.21958360e-02, 3.67097854e-01, 8.05402440e-01,\n",
              "         6.64266665e-01],\n",
              "        [3.23764512e-01, 5.28360610e-01, 9.98720324e-01, 1.22637900e-01,\n",
              "         5.39226593e-01]]), array([[2.64248566, 4.15463826],\n",
              "        [3.00786825, 3.95267184],\n",
              "        [2.40074716, 4.12377691],\n",
              "        [2.27187191, 4.29293401],\n",
              "        [1.93319717, 4.39063015],\n",
              "        [2.00019622, 4.26879539],\n",
              "        [2.20401834, 4.33064232],\n",
              "        [2.1404919 , 4.28949022],\n",
              "        [2.27530068, 4.25193523],\n",
              "        [2.46319636, 4.28030645],\n",
              "        [3.30138184, 3.60956758],\n",
              "        [2.45665874, 3.98644235],\n",
              "        [2.68719068, 3.96962993],\n",
              "        [2.13324116, 4.24162893],\n",
              "        [3.07980717, 3.87933632],\n",
              "        [2.41386003, 4.30085044],\n",
              "        [1.51963496, 4.68780349],\n",
              "        [3.27302648, 3.66213847],\n",
              "        [1.47975166, 4.65365658],\n",
              "        [1.73483343, 4.57091615],\n",
              "        [1.93010803, 4.21609807],\n",
              "        [2.04514853, 4.30032216],\n",
              "        [2.90077624, 3.77023953],\n",
              "        [1.93210391, 4.28916535],\n",
              "        [1.45766983, 4.73350975],\n",
              "        [2.39917448, 4.25615584],\n",
              "        [2.62671049, 4.12127319],\n",
              "        [2.29508573, 4.22164693],\n",
              "        [2.02219446, 4.23111545],\n",
              "        [2.70969881, 4.17501326],\n",
              "        [3.00879236, 3.80387265],\n",
              "        [2.74837493, 3.79181907],\n",
              "        [2.29917217, 4.30850721],\n",
              "        [1.8199129 , 4.44326687],\n",
              "        [2.32011023, 4.04535997],\n",
              "        [1.78740521, 4.27940326],\n",
              "        [1.89221213, 4.29068159],\n",
              "        [2.62825085, 3.97774566],\n",
              "        [2.09798624, 4.19251384],\n",
              "        [2.24784255, 4.29100346],\n",
              "        [2.22585814, 4.42614255],\n",
              "        [2.25242781, 4.14412679],\n",
              "        [1.84677632, 4.62516916],\n",
              "        [2.21068476, 4.09382424],\n",
              "        [1.27061475, 4.75892045],\n",
              "        [2.06207211, 4.24924864],\n",
              "        [2.09465232, 4.27641672],\n",
              "        [2.1324893 , 4.11836466],\n",
              "        [0.88010714, 4.89710163],\n",
              "        [1.48371028, 4.69669448],\n",
              "        [2.22924028, 4.1855222 ],\n",
              "        [1.44574611, 4.68623037],\n",
              "        [1.81802588, 4.4966125 ],\n",
              "        [1.40418992, 4.54534378],\n",
              "        [1.61410706, 4.6374547 ],\n",
              "        [2.32822835, 4.13675723],\n",
              "        [2.67994287, 3.93309523],\n",
              "        [2.13712136, 4.3585243 ],\n",
              "        [2.04022086, 4.45679201],\n",
              "        [1.79756956, 4.44892212],\n",
              "        [2.7371317 , 4.07526511],\n",
              "        [1.5552164 , 4.59353348],\n",
              "        [2.69931002, 3.96822912],\n",
              "        [1.90237097, 4.45784864],\n",
              "        [2.59237464, 4.14013597],\n",
              "        [2.70423683, 3.98691861],\n",
              "        [1.67649723, 4.49239964],\n",
              "        [2.34957513, 4.3247671 ],\n",
              "        [2.33458666, 4.13195111],\n",
              "        [3.29859781, 3.54979215],\n",
              "        [1.92800917, 4.37920155],\n",
              "        [1.40208028, 4.66925639],\n",
              "        [1.72004388, 4.37902966],\n",
              "        [1.59741411, 4.6643127 ],\n",
              "        [2.46685408, 4.15705018],\n",
              "        [1.67853864, 4.66260902],\n",
              "        [2.01541627, 4.29379303],\n",
              "        [2.78035638, 3.95549962],\n",
              "        [2.65982993, 3.86476848],\n",
              "        [2.72100185, 4.01624723],\n",
              "        [2.13262079, 4.40333551],\n",
              "        [2.1731101 , 4.39374118],\n",
              "        [1.97569719, 4.33500945],\n",
              "        [1.94217777, 4.24731816],\n",
              "        [2.30404601, 4.37773432],\n",
              "        [2.2294201 , 4.04988768],\n",
              "        [2.5782291 , 4.02799296],\n",
              "        [2.17327328, 4.26209913],\n",
              "        [2.11619558, 4.20898075],\n",
              "        [2.96209561, 3.87554651],\n",
              "        [2.21820033, 4.22354935],\n",
              "        [2.31518481, 4.32054033],\n",
              "        [2.20881061, 4.19133251],\n",
              "        [2.27024466, 4.25977401],\n",
              "        [3.12965918, 3.77186484],\n",
              "        [2.02662549, 4.52719752],\n",
              "        [2.78875627, 3.85830267],\n",
              "        [2.23164705, 4.27156907],\n",
              "        [1.32376635, 4.75846783],\n",
              "        [2.50630236, 4.02920286],\n",
              "        [1.79375312, 4.61751667],\n",
              "        [2.99595623, 3.85497381],\n",
              "        [2.83515882, 3.87148855],\n",
              "        [2.50323979, 4.15892282],\n",
              "        [1.75344579, 4.55482727],\n",
              "        [3.13540617, 3.49819457],\n",
              "        [3.57307074, 3.47573785],\n",
              "        [1.98526718, 4.29656953],\n",
              "        [2.38698372, 4.16381821],\n",
              "        [2.22988898, 4.28031472],\n",
              "        [2.40482479, 4.31301492],\n",
              "        [2.46567737, 4.19323129],\n",
              "        [2.09781334, 4.13607418],\n",
              "        [2.60880887, 4.02656206],\n",
              "        [1.74241309, 4.54140444],\n",
              "        [2.83829915, 3.98160824],\n",
              "        [1.36686307, 4.7318606 ],\n",
              "        [2.55755367, 4.02077575],\n",
              "        [2.82149219, 4.00171796],\n",
              "        [1.89014474, 4.30190606],\n",
              "        [2.28270394, 4.39387624],\n",
              "        [2.33642395, 4.19915315],\n",
              "        [2.05287244, 4.06508334],\n",
              "        [2.76237483, 4.08848882],\n",
              "        [2.40228475, 4.20729206],\n",
              "        [3.17819735, 3.63655256],\n",
              "        [1.75761586, 4.53002156],\n",
              "        [2.15278358, 4.49321748],\n",
              "        [2.51674525, 4.0280473 ],\n",
              "        [2.95102146, 3.91803129],\n",
              "        [2.63266948, 4.04345326],\n",
              "        [2.56562987, 4.20520702],\n",
              "        [2.63586763, 4.11251618],\n",
              "        [2.36574513, 4.16773259],\n",
              "        [2.59190608, 3.97803542],\n",
              "        [2.68840498, 3.93319003],\n",
              "        [3.21279662, 3.75923714],\n",
              "        [2.26391127, 4.39575133],\n",
              "        [2.72679185, 3.95165962],\n",
              "        [1.8330561 , 4.28830445],\n",
              "        [1.860645  , 4.40793939],\n",
              "        [3.15180765, 3.84273639],\n",
              "        [2.1872826 , 4.34047131],\n",
              "        [2.75211436, 3.98057559],\n",
              "        [3.11264488, 3.87752203],\n",
              "        [1.69293623, 4.61263632],\n",
              "        [2.22655757, 4.13115576],\n",
              "        [2.57465763, 4.11317738],\n",
              "        [2.13530971, 4.3855824 ],\n",
              "        [2.29442588, 4.39612661],\n",
              "        [2.78330441, 3.8828704 ],\n",
              "        [1.97217145, 4.38624533],\n",
              "        [1.83319081, 4.45916688],\n",
              "        [2.75169798, 4.13391293],\n",
              "        [2.3446494 , 4.20530275],\n",
              "        [1.53022858, 4.49817919],\n",
              "        [3.35718816, 3.61563504],\n",
              "        [3.15495789, 3.85970337],\n",
              "        [1.9008061 , 4.39659443],\n",
              "        [2.298838  , 4.20365331]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYjifVRqbLMr"
      },
      "source": [
        "# Structure your model\n",
        "Create a class to define and use a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Fv2md1YyKx"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model as Model_\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# define a model structure\n",
        "class Model(Model_):\n",
        "  def __init__(self, neurons=[12,12,3], reg=None): # define the structure with number of neurons in each hidden layer\n",
        "    super(Model, self).__init__()\n",
        "    self.denseLayers=[]\n",
        "    for neuron in neurons: # for each hidden layer, add a dense layer of size with a number of neurons\n",
        "      self.denseLayers.append(Dense(neuron, activation=None))\n",
        "    #self.outputLayer = Dense(2, activation=None, kernel_regularizer = reg) # if we were to add regularization in the layer\n",
        "    # self.regularizer = #can I also define regularizer as a separate hyperparameter?\n",
        "    self.outputLayer = Dense(2, activation=None) # a final layer with 2 neurons and no activation function\n",
        "  \n",
        "  # to use the model \n",
        "  def call(self, input_x):\n",
        "    output = input_x\n",
        "    for layer in self.denseLayers:\n",
        "      output = layer(output)\n",
        "    return self.outputLayer(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG8wbG2IbT2_"
      },
      "source": [
        "# Create an optimization routine\n",
        "Define optimization steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaVxN-qMaY9v"
      },
      "source": [
        "# optimizer defined with model, regularizer, minibatch, learning rate, and loss\n",
        "class Optimizer:\n",
        "  def __init__(self, model, reg = None, mb = 8, lr = 0.001, loss = tf.keras.losses.MeanSquaredError, opt=tf.keras.optimizers.Adam):\n",
        "    self.model     = model\n",
        "    #self.l1 = l1\n",
        "    #self.l2 = l2\n",
        "    self.reg = reg # regularization parameter as one of the hyperparameters\n",
        "    self.loss      = loss() #tf.keras.losses.MeanSquaredError()\n",
        "    self.optimizer = opt(learning_rate = lr)\n",
        "    self.mb        = mb\n",
        "\n",
        "    self.train_loss     = tf.keras.metrics.Mean(name='train_loss')\n",
        "    self.train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "    self.test_loss     = tf.keras.metrics.Mean(name='test_loss')\n",
        "    self.test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "  \n",
        "  @tf.function\n",
        "  def train_step(self, x , y):\n",
        "    with tf.GradientTape() as tape: # to watch the trainable variables of model and record the operations for performing automatic differentiation\n",
        "      predictions = model(x)\n",
        "      #loss = self.loss(y, predictions)\n",
        "      loss = self.loss(y, predictions) + self.reg * tf.convert_to_tensor([tf.reduce_sum(abs(v)) for v in self.model.trainable_variables])\n",
        "      # loss function for l1 regularization\n",
        "      #loss = self.loss(y, predictions) + self.reg * tf.convert_to_tensor([tf.reduce_sum(square(v)) for v in self.model.trainable_variables])\n",
        "      # loss function for l2 regularization\n",
        "      #regularizer_loss = loss + tf.add_n(l2_model.losses)\n",
        "    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "    self.train_loss(loss)\n",
        "    # self.train_accuracy(y, predictions)\n",
        "    return loss\n",
        "\n",
        "  @tf.function\n",
        "  def test_step(self, x , y):\n",
        "    predictions = self.model(x)\n",
        "    #loss = self.loss(y, predictions)\n",
        "    loss = self.loss(y, predictions) + self.reg * tf.convert_to_tensor([tf.reduce_sum(abs(v)) for v in self.model.trainable_variables])\n",
        "    #loss = self.loss(y, predictions) + self.reg * tf.convert_to_tensor([tf.reduce_sum(abs(v)) for v in self.model.trainable_variables])\n",
        "    self.test_loss(loss)\n",
        "    # self.test_accuracy(y, predictions)\n",
        "\n",
        "  def train (self):# for each mini batch, make predictions for train set and calculate loss (which is an average of the loss values in the batch)\n",
        "    for mbX, mbY in self.train_ds:\n",
        "      self.train_step(mbX, mbY)\n",
        "  \n",
        "  def test  (self): # for each mini batch, make predictions for test set and calculate loss (which is an average of the loss values in the batch)\n",
        "    for mbX, mbY in self.test_ds:\n",
        "      self.test_step(mbX, mbY)    \n",
        "  \n",
        "  def run   (self, dataX, dataY, testX, testY, epochs, verbose=2):\n",
        "    historyTR = []\n",
        "    historyTS = []\n",
        "    template = '{} {}, {}: {}, {}: {}'\n",
        "    # generate batches with the shuffled data from train set and from test set, respectively\n",
        "    self.train_ds = tf.data.Dataset.from_tensor_slices((dataX, dataY)).shuffle(16000).batch(self.mb)\n",
        "    self.test_ds  = tf.data.Dataset.from_tensor_slices((testX,testY)).batch(self.mb)\n",
        "    for i in range(epochs):\n",
        "      \n",
        "      self.train ()\n",
        "    #   print(lossTR)\n",
        "      self.test  ()\n",
        "      # if verbose, print loss values for each epoch\n",
        "      if verbose > 0:\n",
        "        print(template.format(\"epoch: \", i+1,\n",
        "                      \" TRAIN LOSS: \", self.train_loss.result(),\n",
        "                      \" TEST LOSS: \" , self.test_loss.result()))\n",
        "                      # \" TRAIN ACC: \" , self.train_accuracy.result()*100,\n",
        "                      # \" TEST ACC: \"  , self.test_accuracy.result()*100)\n",
        "        # )\n",
        "      \n",
        "      temp = '{}'\n",
        "      # append loss values for train and test loss histories\n",
        "      historyTR.append(float(temp.format(self.train_loss.result())))\n",
        "      historyTS.append(float(temp.format(self.test_loss.result() )))\n",
        "\n",
        "      # has to reset states for each epoch\n",
        "      self.train_loss.reset_states()\n",
        "      self.train_accuracy.reset_states()\n",
        "      self.test_loss.reset_states()\n",
        "      self.test_accuracy.reset_states()\n",
        "    return historyTR, historyTS # train loss values and test loss values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLQQTXhZb2N4"
      },
      "source": [
        "# Structure your calls\n",
        "Here you should make the main calls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH38m2ykb18C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6c556d-0ebe-42b6-bb78-4125d52787e1"
      },
      "source": [
        "x  , y  = loadTrainData ()\n",
        "xt , yt = loadTestData  ()\n",
        "\n",
        "# initiate a model instance\n",
        "#model  = Model (reg='l1')\n",
        "model  = Model ()\n",
        "# initiate an optimzer instance to run\n",
        "opt    = Optimizer (model, reg = 0.01, mb = 8, lr = 0.000001, loss = tf.keras.losses.MeanSquaredError, opt=tf.keras.optimizers.Adam)\n",
        "# or just: $ opt    = Optimizer (model)\n",
        "\n",
        "# get train and test loss values after running the optimizer\n",
        "tr, ts = opt.run (x, y, xt, yt, 100, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch:  1,  TRAIN LOSS: : 8.839407920837402,  TEST LOSS: : 8.863236427307129\n",
            "epoch:  2,  TRAIN LOSS: : 8.514732360839844,  TEST LOSS: : 8.549068450927734\n",
            "epoch:  3,  TRAIN LOSS: : 8.192831993103027,  TEST LOSS: : 8.237239837646484\n",
            "epoch:  4,  TRAIN LOSS: : 7.873526573181152,  TEST LOSS: : 7.927468299865723\n",
            "epoch:  5,  TRAIN LOSS: : 7.556050777435303,  TEST LOSS: : 7.618978977203369\n",
            "epoch:  6,  TRAIN LOSS: : 7.240401268005371,  TEST LOSS: : 7.312222957611084\n",
            "epoch:  7,  TRAIN LOSS: : 6.927315711975098,  TEST LOSS: : 7.007969856262207\n",
            "epoch:  8,  TRAIN LOSS: : 6.616818428039551,  TEST LOSS: : 6.705690860748291\n",
            "epoch:  9,  TRAIN LOSS: : 6.309145450592041,  TEST LOSS: : 6.4061126708984375\n",
            "epoch:  10,  TRAIN LOSS: : 6.004301071166992,  TEST LOSS: : 6.108740329742432\n",
            "epoch:  11,  TRAIN LOSS: : 5.702305316925049,  TEST LOSS: : 5.813876628875732\n",
            "epoch:  12,  TRAIN LOSS: : 5.4032511711120605,  TEST LOSS: : 5.5214738845825195\n",
            "epoch:  13,  TRAIN LOSS: : 5.107160568237305,  TEST LOSS: : 5.231554985046387\n",
            "epoch:  14,  TRAIN LOSS: : 4.814298629760742,  TEST LOSS: : 4.944564342498779\n",
            "epoch:  15,  TRAIN LOSS: : 4.525444984436035,  TEST LOSS: : 4.661353588104248\n",
            "epoch:  16,  TRAIN LOSS: : 4.241471290588379,  TEST LOSS: : 4.382674217224121\n",
            "epoch:  17,  TRAIN LOSS: : 3.963006019592285,  TEST LOSS: : 4.1091108322143555\n",
            "epoch:  18,  TRAIN LOSS: : 3.6907644271850586,  TEST LOSS: : 3.8413174152374268\n",
            "epoch:  19,  TRAIN LOSS: : 3.425647497177124,  TEST LOSS: : 3.5802884101867676\n",
            "epoch:  20,  TRAIN LOSS: : 3.168394088745117,  TEST LOSS: : 3.326643705368042\n",
            "epoch:  21,  TRAIN LOSS: : 2.9201598167419434,  TEST LOSS: : 3.0816402435302734\n",
            "epoch:  22,  TRAIN LOSS: : 2.6817822456359863,  TEST LOSS: : 2.8458447456359863\n",
            "epoch:  23,  TRAIN LOSS: : 2.454115629196167,  TEST LOSS: : 2.6202995777130127\n",
            "epoch:  24,  TRAIN LOSS: : 2.238433837890625,  TEST LOSS: : 2.406123638153076\n",
            "epoch:  25,  TRAIN LOSS: : 2.0359368324279785,  TEST LOSS: : 2.2047765254974365\n",
            "epoch:  26,  TRAIN LOSS: : 1.8476107120513916,  TEST LOSS: : 2.0167622566223145\n",
            "epoch:  27,  TRAIN LOSS: : 1.6746176481246948,  TEST LOSS: : 1.8437631130218506\n",
            "epoch:  28,  TRAIN LOSS: : 1.5182816982269287,  TEST LOSS: : 1.6862140893936157\n",
            "epoch:  29,  TRAIN LOSS: : 1.3793340921401978,  TEST LOSS: : 1.5457087755203247\n",
            "epoch:  30,  TRAIN LOSS: : 1.2589144706726074,  TEST LOSS: : 1.4231420755386353\n",
            "epoch:  31,  TRAIN LOSS: : 1.1580173969268799,  TEST LOSS: : 1.31972336769104\n",
            "epoch:  32,  TRAIN LOSS: : 1.0762468576431274,  TEST LOSS: : 1.234429121017456\n",
            "epoch:  33,  TRAIN LOSS: : 1.0118244886398315,  TEST LOSS: : 1.1655328273773193\n",
            "epoch:  34,  TRAIN LOSS: : 0.9628176689147949,  TEST LOSS: : 1.111942172050476\n",
            "epoch:  35,  TRAIN LOSS: : 0.9260866045951843,  TEST LOSS: : 1.0699923038482666\n",
            "epoch:  36,  TRAIN LOSS: : 0.8982532024383545,  TEST LOSS: : 1.0372302532196045\n",
            "epoch:  37,  TRAIN LOSS: : 0.8768337368965149,  TEST LOSS: : 1.011091947555542\n",
            "epoch:  38,  TRAIN LOSS: : 0.8598081469535828,  TEST LOSS: : 0.9897705912590027\n",
            "epoch:  39,  TRAIN LOSS: : 0.845872700214386,  TEST LOSS: : 0.972198486328125\n",
            "epoch:  40,  TRAIN LOSS: : 0.834176778793335,  TEST LOSS: : 0.9572040438652039\n",
            "epoch:  41,  TRAIN LOSS: : 0.8238821625709534,  TEST LOSS: : 0.9437386393547058\n",
            "epoch:  42,  TRAIN LOSS: : 0.8146452903747559,  TEST LOSS: : 0.931887149810791\n",
            "epoch:  43,  TRAIN LOSS: : 0.8062742948532104,  TEST LOSS: : 0.9211105108261108\n",
            "epoch:  44,  TRAIN LOSS: : 0.7984941601753235,  TEST LOSS: : 0.9109736680984497\n",
            "epoch:  45,  TRAIN LOSS: : 0.7910700440406799,  TEST LOSS: : 0.9014756083488464\n",
            "epoch:  46,  TRAIN LOSS: : 0.7841196656227112,  TEST LOSS: : 0.8925375938415527\n",
            "epoch:  47,  TRAIN LOSS: : 0.7774381637573242,  TEST LOSS: : 0.8840545415878296\n",
            "epoch:  48,  TRAIN LOSS: : 0.7709158658981323,  TEST LOSS: : 0.8757945895195007\n",
            "epoch:  49,  TRAIN LOSS: : 0.7646340727806091,  TEST LOSS: : 0.8680282831192017\n",
            "epoch:  50,  TRAIN LOSS: : 0.7585188150405884,  TEST LOSS: : 0.8603476285934448\n",
            "epoch:  51,  TRAIN LOSS: : 0.7525914907455444,  TEST LOSS: : 0.8531443476676941\n",
            "epoch:  52,  TRAIN LOSS: : 0.7468547224998474,  TEST LOSS: : 0.8460499048233032\n",
            "epoch:  53,  TRAIN LOSS: : 0.7411648035049438,  TEST LOSS: : 0.8391066789627075\n",
            "epoch:  54,  TRAIN LOSS: : 0.7355859875679016,  TEST LOSS: : 0.8322798609733582\n",
            "epoch:  55,  TRAIN LOSS: : 0.7300882935523987,  TEST LOSS: : 0.8256039619445801\n",
            "epoch:  56,  TRAIN LOSS: : 0.7246806621551514,  TEST LOSS: : 0.8189421892166138\n",
            "epoch:  57,  TRAIN LOSS: : 0.7192873358726501,  TEST LOSS: : 0.8123878240585327\n",
            "epoch:  58,  TRAIN LOSS: : 0.7139747142791748,  TEST LOSS: : 0.8059263229370117\n",
            "epoch:  59,  TRAIN LOSS: : 0.7087834477424622,  TEST LOSS: : 0.7996295690536499\n",
            "epoch:  60,  TRAIN LOSS: : 0.7037171721458435,  TEST LOSS: : 0.7935353517532349\n",
            "epoch:  61,  TRAIN LOSS: : 0.6987178921699524,  TEST LOSS: : 0.7875398397445679\n",
            "epoch:  62,  TRAIN LOSS: : 0.693830668926239,  TEST LOSS: : 0.781693160533905\n",
            "epoch:  63,  TRAIN LOSS: : 0.6890206336975098,  TEST LOSS: : 0.7759284377098083\n",
            "epoch:  64,  TRAIN LOSS: : 0.6843093633651733,  TEST LOSS: : 0.7702091932296753\n",
            "epoch:  65,  TRAIN LOSS: : 0.6796258091926575,  TEST LOSS: : 0.7645488977432251\n",
            "epoch:  66,  TRAIN LOSS: : 0.6749734878540039,  TEST LOSS: : 0.758929431438446\n",
            "epoch:  67,  TRAIN LOSS: : 0.6703901886940002,  TEST LOSS: : 0.7534216046333313\n",
            "epoch:  68,  TRAIN LOSS: : 0.6659228801727295,  TEST LOSS: : 0.7480138540267944\n",
            "epoch:  69,  TRAIN LOSS: : 0.6615377068519592,  TEST LOSS: : 0.7426720857620239\n",
            "epoch:  70,  TRAIN LOSS: : 0.657172679901123,  TEST LOSS: : 0.7373507022857666\n",
            "epoch:  71,  TRAIN LOSS: : 0.6528401970863342,  TEST LOSS: : 0.7320858836174011\n",
            "epoch:  72,  TRAIN LOSS: : 0.6485814452171326,  TEST LOSS: : 0.7268987894058228\n",
            "epoch:  73,  TRAIN LOSS: : 0.6443982124328613,  TEST LOSS: : 0.7218133211135864\n",
            "epoch:  74,  TRAIN LOSS: : 0.6402742862701416,  TEST LOSS: : 0.7168945670127869\n",
            "epoch:  75,  TRAIN LOSS: : 0.636185348033905,  TEST LOSS: : 0.7118310332298279\n",
            "epoch:  76,  TRAIN LOSS: : 0.6321210265159607,  TEST LOSS: : 0.7069913148880005\n",
            "epoch:  77,  TRAIN LOSS: : 0.6280776858329773,  TEST LOSS: : 0.7020772695541382\n",
            "epoch:  78,  TRAIN LOSS: : 0.624087929725647,  TEST LOSS: : 0.6972184181213379\n",
            "epoch:  79,  TRAIN LOSS: : 0.6202155351638794,  TEST LOSS: : 0.6925185918807983\n",
            "epoch:  80,  TRAIN LOSS: : 0.6163403391838074,  TEST LOSS: : 0.6877452731132507\n",
            "epoch:  81,  TRAIN LOSS: : 0.6125444769859314,  TEST LOSS: : 0.6831409931182861\n",
            "epoch:  82,  TRAIN LOSS: : 0.6088293790817261,  TEST LOSS: : 0.6786242723464966\n",
            "epoch:  83,  TRAIN LOSS: : 0.6051817536354065,  TEST LOSS: : 0.674177348613739\n",
            "epoch:  84,  TRAIN LOSS: : 0.6015117168426514,  TEST LOSS: : 0.6697396636009216\n",
            "epoch:  85,  TRAIN LOSS: : 0.5978516936302185,  TEST LOSS: : 0.6652383804321289\n",
            "epoch:  86,  TRAIN LOSS: : 0.5942705869674683,  TEST LOSS: : 0.6608409881591797\n",
            "epoch:  87,  TRAIN LOSS: : 0.5907199382781982,  TEST LOSS: : 0.6565266847610474\n",
            "epoch:  88,  TRAIN LOSS: : 0.587191104888916,  TEST LOSS: : 0.6522404551506042\n",
            "epoch:  89,  TRAIN LOSS: : 0.5836976766586304,  TEST LOSS: : 0.6479483842849731\n",
            "epoch:  90,  TRAIN LOSS: : 0.5802539587020874,  TEST LOSS: : 0.643733024597168\n",
            "epoch:  91,  TRAIN LOSS: : 0.5768052935600281,  TEST LOSS: : 0.6395624876022339\n",
            "epoch:  92,  TRAIN LOSS: : 0.5734336376190186,  TEST LOSS: : 0.6354556083679199\n",
            "epoch:  93,  TRAIN LOSS: : 0.5701333284378052,  TEST LOSS: : 0.6314656138420105\n",
            "epoch:  94,  TRAIN LOSS: : 0.5668257474899292,  TEST LOSS: : 0.6274297833442688\n",
            "epoch:  95,  TRAIN LOSS: : 0.5635446906089783,  TEST LOSS: : 0.6233431100845337\n",
            "epoch:  96,  TRAIN LOSS: : 0.5602713227272034,  TEST LOSS: : 0.6193519830703735\n",
            "epoch:  97,  TRAIN LOSS: : 0.5570257306098938,  TEST LOSS: : 0.6154183745384216\n",
            "epoch:  98,  TRAIN LOSS: : 0.5538138747215271,  TEST LOSS: : 0.6114940643310547\n",
            "epoch:  99,  TRAIN LOSS: : 0.5506452322006226,  TEST LOSS: : 0.6076685190200806\n",
            "epoch:  100,  TRAIN LOSS: : 0.5475001931190491,  TEST LOSS: : 0.6037973761558533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5esr5sE3r3Uh"
      },
      "source": [
        "tf.keras.backend.set_floatx('float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lROgCU6BEoh"
      },
      "source": [
        "# PLOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEax4t3y_hSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4b6d8d3f-8e2f-4863-9d42-c566fb0e01d3"
      },
      "source": [
        "# print train and test loss over epoch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "print(matplotlib.__version__)\n",
        "plt.plot(ts, label='TEST')\n",
        "plt.plot(tr, label='TRAIN')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXhfGOLpUCuW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "f0a032ab-30d0-4c12-954d-3b3be1dea2bd"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/DLLab/') # CHANGE THIS LINE DEPENDING OF WHERE YOU PUT YOUR FILES IN GOOGLE DRIVE\n",
        "\n",
        "from run import run_experiment\n",
        "run_experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-aee9968b7ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/DLLab/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# CHANGE THIS LINE DEPENDING OF WHERE YOU PUT YOUR FILES IN GOOGLE DRIVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'run'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYXjLKmvVCHT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}